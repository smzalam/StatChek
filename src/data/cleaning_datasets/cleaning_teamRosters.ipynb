{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../scraped_csv/team_rosters/20162017_team_roster.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at dataset, there are a couple of things we need to do:\n",
    "- Find and remove null values\n",
    "- Remove the .0 at the end of the jersey numbers\n",
    "- Delete the columns not fitting in the database schema\n",
    "- Rename column names to align with database schema\n",
    "\n",
    "So let's go ahead and do these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null values\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one null value, thus it is acceptable to use the `dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the .0 at the end of jersey numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the .0 at the end of the jersey numbers\n",
    "df['jerseyNumber'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .0 exists as it is a float. We need to change the type to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'jerseyNumber':np.int64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the columns not fitting in the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = [\n",
    "    'person.link', \n",
    "    'position.code', \n",
    "    'position.type',\n",
    "    'position.abbreviation' \n",
    "]\n",
    "df = df.drop(columns=dropped_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename column names to align with database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_columns = {\n",
    "    'person.id': 'apiID', \n",
    "    'person.fullName': 'name', \n",
    "    'position.name': 'position', \n",
    "}\n",
    "df = df.rename(columns=renamed_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating extra columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make querying easier, we want to create two extra fields: \n",
    "- First Name\n",
    "- Last Name\n",
    "\n",
    "We will achieve this by:\n",
    "- Getting full name list from dataframe\n",
    "- Splitting full name into two lists: `firstName` and `lastName`\n",
    "- Assigning the two lists as columns in the dataframe\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting full name list from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullName = df['name'].tolist()\n",
    "fullName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting full name into two lists: `firstName` and `lastName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the two lists\n",
    "firstName = list(map(lambda x: x.split(\" \")[0], fullName))\n",
    "print(firstName)\n",
    "lastName = list(map(lambda x: x.split(\" \")[1], fullName))\n",
    "print(lastName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the two lists as columns in the dataframe\n",
    "df['firstName'] = firstName\n",
    "df['lastName'] = lastName\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check if the csv shows up as we want to in the format it will be inserted into the database in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = df.to_dict(orient='records')\n",
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to apply the above modifications to all the other roster datasets and then combine them all into one csv file to fit the database schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will be done by making a general function and then looping through it to connect all the datasets that:\n",
    "- Applies modifications to each dataset\n",
    "- Merges all the datasets together with their year number to fit database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making function\n",
    "\n",
    "def cleaning_dataset(dataframe): \n",
    "    df = pd.read_csv(dataframe)\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = df.astype({'jerseyNumber':np.int64})\n",
    "\n",
    "    dropped_columns = [\n",
    "        'person.link', \n",
    "        'position.code', \n",
    "        'position.type',\n",
    "        'position.abbreviation' \n",
    "    ]\n",
    "    df = df.drop(columns=dropped_columns)\n",
    "\n",
    "    renamed_columns = {\n",
    "        'person.id': 'apiID', \n",
    "        'person.fullName': 'name', \n",
    "        'position.name': 'position', \n",
    "    }\n",
    "    df = df.rename(columns=renamed_columns)\n",
    "\n",
    "    fullName = df['name'].tolist()\n",
    "    firstName = list(map(lambda x: x.split(\" \")[0], fullName))\n",
    "    lastName = list(map(lambda x: x.split(\" \")[1], fullName))\n",
    "    df['firstName'] = firstName\n",
    "    df['lastName'] = lastName\n",
    "\n",
    "    return df.to_dict(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all roster datasets\n",
    "roster_datasets_seasons = list(map(lambda x: x.split(\"_\")[0], os.listdir(\"../scraped_csv/team_rosters/\")))\n",
    "roster_datasets_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for every roster dataset\n",
    "all_rosters = {}\n",
    "for season in roster_datasets_seasons:\n",
    "    all_rosters[f'{season}'] = cleaning_dataset(f\"../scraped_csv/team_rosters/{season}_team_roster.csv\")\n",
    "df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in all_rosters.items() ]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "df = df.replace(np.NaN, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets finally export the cleansed dataframe into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = '../cleaned_csv/teamAllRosterDetailsCleaned.csv'\n",
    "df.to_csv(title, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get csv back into dataframe\n",
    "\n",
    "a = pd.read_csv('../cleaned_csv/teamAllRosterDetailsCleaned.csv')\n",
    "b = a.to_dict(orient='list')\n",
    "c = pd.DataFrame.from_dict(b)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
